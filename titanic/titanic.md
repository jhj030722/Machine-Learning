# 모델 학습 시 고려사항 가이드

 모델이 우수한 성능을 낸다고 하더라도, 그 이유를 분석가/사이언티스트가 이해하고 있지 못한다면 결코 의미있지 않습니다. 코드를 짜는 시간보다 고민하는 데에 더 많은 시간을 할애하셨으면 합니다. 또 결과를 통해 증명하기보다 본인의 논리를 믿고 따르는 습관을 들이면 좋겠습니다. 예상과 다르다면 다시 학습해가면 됩니다.

 모든 부분에 힘을 주실 필요가 없습니다. 


--------

모델을 학습할 때는 다양한 요소를 고려해야 합니다. 이는 데이터의 전처리부터 모델의 선택과 평가에 이르기까지 여러 단계에 걸쳐 영향을 미칩니다. 아래는 주요한 요소들을 설명합니다.

1. 결측치 처리
> 🧞‍♀️ 시각화 등으로 결측치를 확인해주세요. 각 열의 결측치를 대체한 방법과 왜 그 방법을 사용했는지에 관하여 논리적으로 서술해주세요.

결측치 확인하기: 
시각화: 

2. 데이터 인코딩
범주형 변수는 모델이 이해할 수 있는 숫자 형태로 변환해야 합니다. 대표적인 방법으로는 Label Encoding(위계가 있는 경우)과 One-Hot Encoding(순서가 없는 경우)이 있습니다. 타겟 인코딩은 범주형 피처를 타겟 변수의 평균이나 비율로 인코딩하는 방법입니다. 타겟 변수가 특정 값일 확률을 사용하기도 합니다.

> 🧞‍♀️ 범주형 변수에 대해서 인코딩을 수행하셨다면 어떤 칼럼에 대해, 어떤 인코딩 방법을 사용하였는지 논리적으로 설명해주세요. (이때, 고려했던 인코딩 방법과 선택하지 않은 이유를 함께 제시해주세요.)

3. 데이터 스케일링

> 🧞‍♀️ 해당 데이터의 정규화 필요성에 대하여 논의해주세요. 해당 분포를 모델링에 적합한 형태로 변환하기 위해 사용한 스케일링 방식에 대해 설명해주세요.
> (ex. MinMax 스케일링은 이상치에 관하여 민감하므로, 그렇지 않은 ~ 방법을 사용했습니다.)

4. 데이터 왜도
왜도(skewness) 처리: 데이터가 비대칭적으로 분포되어 있을 때 로그 변환, 박스-콕스(Box-Cox) 변환 등을 사용해 왜도를 줄일 수 있습니다. 왜도가 크면 모델의 성능이 저하될 수 있습니다.

> 🧞‍♀️ 어떤 경우에 어떤 왜도 처리를 하는지 공부해보세요. 해당 데이터의 분포를 나타내는 시각화를 진행하고, 왜도를 수치로 표현해보세요.
타이타닉 데이터셋의 각 수치형 컬럼에는 왜도 처리가 필요한가요? 왜 그렇게 판단했나요?

5. 이상치(Outliers)
이상치 처리: 이상치는 모델에 부정적인 영향을 줄 수 있기 때문에 이를 식별하고 처리하는 것이 중요합니다. 이상치를 제거하거나, 다른 값으로 대체(예: 중앙값)하는 방법이 있습니다. 이상치가 반드시 잘못된 것은 아니므로 주의해야 합니다.

> 🧞‍♀️ 이상치를 처리하였나요? 어떤 기준으로 이상치를 판단하였나요?


6. 피처 선택 및 생성
피처 선택(Feature Selection): 모델 성능을 개선하거나 과적합을 방지하기 위해 불필요한 피처를 제거합니다. 이를 위해 통계적 방법(예: p-value), 모델 기반 방법(예: L1 정규화), 또는 피처 중요도를 활용합니다.

피처 생성(Feature Engineering): 모델 성능을 높이기 위해 새로운 피처를 생성할 수 있습니다. 예를 들어, 두 피처를 곱하거나 나누어 새로운 피처를 만들 수 있습니다.

> 🧞‍♀️ 새로 만든 피쳐가 있다면 자랑해주세요.

> 🧞‍♀️ 다중공선성이 있다고 판단되는 지표가 있었나요? 왜 그렇게 생각하셨으며, 어떻게 처리하셨나요?

7. 데이터 분할
훈련/검증/테스트 데이터 분할: 데이터셋을 훈련, 검증, 테스트 세트로 나누어 모델의 성능을 평가합니다. 일반적으로 70-80%를 훈련 데이터로 사용하고, 나머지를 검증과 테스트 데이터로 사용합니다.

> 🧞‍♀️ 데이터 분할 방법 중 K-Fold Cross-Validation과 Stratified K-fold Cross Validation에 대해 공부해보세요. 최종적으로 어떤 방법을 사용했는지, 왜 사용했는지에 대해 서술해주세요.

8. 모델 선택
모델 유형 선택: 데이터의 특성에 따라 적합한 모델을 선택해야 합니다. 예를 들어, 선형 데이터에는 선형 회귀, 비선형 데이터에는 트리 기반 모델 등이 효과적일 수 있습니다.

> 🧞‍♀️ 해당 데이터가 예측하고자 하는 값이 어떤 유형인지에 관련하여 모델 선정의 논리성을 증명해주세요. 또한, 차안으로 선택할 수 있는 모델이 있다면 추천해주세요.


+ 하이퍼파라미터 튜닝: 각 모델의 하이퍼파라미터를 최적화하여 성능을 극대화할 수 있습니다. 그리드 서치(Grid Search)나 랜덤 서치(Random Search) 등의 방법이 도모됩니다.

9. 모델 평가
평가 지표 선택: 회귀 문제에서는 MSE, MAE, R², 분류 문제에서는 정확도, 정밀도, 재현율, F1-score 등을 사용하여 모델 성능을 평가합니다.
교차 검증(Cross-Validation): 데이터를 여러 번 분할하여 모델을 평가하는 방법입니다. 이를 통해 모델의 일반화 성능을 더 잘 평가할 수 있습니다.

평가 지표의 종류에 대해 공부해보세요. 

10. 과적합 방지
모델의 과적합을 방지하기 위한 여러 방법들이 있습니다.
-정규화(Regularization): L1, L2 정규화를 통해 모델의 복잡도를 조절하여 과적합을 방지합니다.
-드롭아웃(Dropout): 신경망에서 드롭아웃을 사용하여 과적합을 방지할 수 있습니다.
-얼리 스탑핑(Early Stopping): 검증 데이터의 성능이 더 이상 개선되지 않으면 훈련을 조기에 중지합니다.

> 🧞‍♀️ 과적합 방지를 위해 도입한 방법이 있나요? 그 방법의 원리와 장점은 무엇인가요?



-----
공통 질문

1. 그 외, 모델의 성능을 높이기 위하여 기여한 부분에 대해 설명해주세요.


2. 결과가 어땠나요? 그리고 왜 그런 결과가 나왔다고 생각하시나요?


3. 시간이 더 있었다면 어떤 노력을 더 해봤을 것 같나요?